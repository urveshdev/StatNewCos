q25logdata <- logdata[whichtosave,]
?IQR
q25 <- quantile(probemeans, 0.25)
whichtosave <- which(probemeans > q25)
q25logdata <- logdata[whichtosave,]
mydata <- q25logdata[apply(q25logdata, 1, IQR) > 1.5, ]
dim(mydata)
?t
mydata <- t(mydata)
?t
dim(mydata)
?aperm
mydata <- aperm(mydata,c(2,1))
dim(mydata)
mydata <- aperm(mydata,1:2
)
dim(mydata)
mydata <- aperm(mydata)
dim(mydata)
pca <- prcomp(tdata, scale=T)
tdata <- t(mydata)
dim(tdata)
tdata <- t(tdata)
pca <- prcomp(tdata, scale=T)
summpca
summary(pca)
?prcomp
plot(pca$x, type="n")
text(pca$x, rownames(pca$x), cex=0.5)
conditions <- phenoData(eset)$agent
plot(pca$x, type="n")
text(pca$x, labels=conditions, cex=0.5)
pearsonCorr <- as.dist(1 - cor(mydata))
hC <- hclust(pearsonCorr)
plot(hC, labels = sampleNames(eset))
pearsonCorr <- as.dist(1 - cor(mydata))
hC <- hclust(pearsonCorr)
plot(hC, labels = sampleNames(eset))
plot(hC, labels = conditions)
heatmap(mydata, col=greenred(100))
heatmap(mydata, col=greenred(100))
condfactor <- factor(eset$agent)
design <- model.matrix(~0+condfactor)
colnames(design) <- c("ctrl", "tnf")
design
fit <- lmFit(eset, design)
contrastmatrix <- makeContrasts(tnf - ctrl,levels=design)
fit <- contrasts.fit(fit, contrastmatrix)
ebayes <- eBayes(fit)
install.packages('limma')
install.packages("limma")
download.packages("limma")
download.packages("limma", destdir = "./")
condfactor <- factor(eset$agent)
design <- model.matrix(~0+condfactor)
For the columns of the design matrix you could use any names. I choose "ctrl" for the control samples, and "tnf" for the chemically treated.
colnames(design) <- c("ctrl", "tnf")
Check how the matrix looks:
design
fit <- lmFit(eset, design)
library(limma)
library("limma")
install.packages("limma")
design
design$ctrl
design[1,]
design[1]
design[,1]
?length
?which
?sum
?length
results <- decideTests(ebayes)
? decideTests
?decideTests
library(pheatmap)
r <- rlogTransformation(dds)
install.packages(pheatmap)
install.packages("pheatmap")
library(pheatmap)
r <- rlogTransformation(dds)
?reformulate
install.packages("shiny")
library("shiny")
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
library(caret)
adData = data.frame(predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
dim(training0)
dim(training)
dim (testing)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(training$SuperPlasticizer SuperPlasticizer )
hist(training$SuperPlasticizer)
(training$SuperPlasticizer)
names(training)
hist(training$SuperPlast)
training$SuperPlasticizer
training$Age
hist(testing$SuperPlast)
testing$SuperPlast
testing$Superplasticizer
training$Superplasticizer
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
precomp <- preProcess(x = training[grep(pattern = "IL*",x = training),], method = "pca", pcaComp = 0.80)
names(training)
training <- training[grep(names(training), pattern = "^IL"),]
names(training)
grep(names(training), pattern = "^IL")
training <- training[,grep(names(training), pattern = "^IL")]
names(training)
training <- training[,grep(names(training), pattern = "^IL")]
preComp<- preProcess(x = training, method = "pca", pcaComp = var(0.80))
preComp<- preProcess(x = training, method = "pca")
preComp
preComp[1]
preComp[[1]]
preComp<- preProcess(x = training, method = "pca", thresh = 0.80)
preComp[[1]]
preComp
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
training <- training[,grep(names(training), pattern = "^IL")]
preComp<- preProcess(x = training, method = "pca", thresh = 0.80)
preComp
final <- predict(preComp, method = "glm",testing)
final <- predict(object = preComp , newdata = testing, method = "glm")
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
testIndex = createDataPartition(diagnosis, p = 0.50,list=FALSE)
training = adData[-testIndex,]
testing = adData[testIndex,]
dim(training)
dim(testing)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
dim(testing)
dim(training)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis, p = 0.50, list=FALSE)
training = adData[trainIndex,]
testing = adData[-trainIndex,]
?dbscan
install.packages(fpc)
install.packages("fpc")
library(fpc)
?dbbscan
?dbscan
dbscan(ruspini, eps=.3, MinPts=5)
data(ruspini, package="cluster")
dbscan(ruspini, eps=.3, MinPts=5)
db <- dbscan(ruspini, eps=.3, MinPts=5)
plot(ruspini, col=db$cluster+1L)
require(Caret)
require("caret")
?require
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
names(segmentationOriginal$case)
names(segmentationOriginal$Case)
summary(segmentationOriginal$Case)
hea(segmentationOriginal$Case)
head(segmentationOriginal$Case)
train <- segmentationOriginal[segmentationOriginal$Case=="Train",]
test <- segmentationOriginal[segmentationOriginal$Case=="Test",]
dim(train)
dim(test)
seed(125)
set.seed(125)
fit <- train(train ~ ., method = "rpart")
fit <- train(train ~ ., data = train, method = "rpart")
head(train)
names(train)
summar(train$Class)
summary(train$Class)
fit <- train(Class ~ ., data = train, method = "rpart")
sumary(fit)
summary(fit)
plot(fit)
plot(fit, uniform=FALSe)
plot(fit, uniform=FALSE)
rpart.plot(fit, uniform=FALSE)
ffit
fit
nodes(fit)
summary(fit)
plot.rpart(fit)
library(maptree)
install.packages(maptree)
install.packages("maptree")
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
olive
olive
head(olive)
fit <- (Area~., data=olive, method="rpart")
fit <- (Area ~ ., data=olive, method="rpart")
fit <- train(Area ~ ., data=olive, method="rpart")
fit
summary(fit)
newdata = as.data.frame(t(colMeans(olive)))
fit <- train(Area ~ ., data=olive, method="tree")
names(getModelInfo())
olive
head(olive)
fit <- train(Area ~ ., data=olive, method="tree")
predict(fit,newdata = as.data.frame(t(colMeans(olive))))
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
names(trainSA)
fit <- train(chd ~ age + alcohol+ obesity + tobacco + typea + ldl)
fit <- train(chd ~ age + alcohol+ obesity + tobacco + typea + ldl, data = trainSA)
fit <- train(chd ~ age + alcohol+ obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
fit
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
predict1 <- predict(fit, newdata = train)
predict1 <- predict(fit, newdata = trainSA)
missClass = function(values,predict1){sum(((predict1 > 0.5)*1) != values)/length(values)}
missClass
dim(trainSA)
missClass = function(values,predict1){sum(((predict1 > 0.5)*1) != values)/length(values)}
missClass(231,predict1)
missClass(231)
predict1 <- predict(fit, newdata = trainSA)
missClass(231,predict1)
predict1 <- predict(fit, newdata = trainSA)
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(231,predict1)
missClass(10,predict1)
sum(((predict1$chd > 0.5)*1) != 231)/length(231)
names(predict1)
(predict1)
sum(predict1)
names(trainSA)
head(trainSA)
predict1 <- predict(fit, newdata = trainSA)
predict1 <- predict(fit, newdata = testSA)
missClass(231,predict1)
missClass(231,predict2)
predict2 <- predict(fit, newdata = testSA)
missClass(231,predict2)
dim(predict2)
dim(testSA)
missClass = function(values,prediction){sum((prediction > 0.5)*1)/length(values)}
missClass(231,predict2)
missClass(231,predict1)
length(231)
missClass = function(values,prediction){sum((prediction > 0.5)*1)/(values)}
missClass(231,predict1)
missClass(231,predict2)
fit <- train(chd ~ age + alcohol+ obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
predict1 <- predict(fit, newdata = trainSA)
predict2 <- predict(fit, newdata = testSA)
missClass(231,predict1)
missClass(231,predict2)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.sedd(33833)
set.seed(33833)
vowel.test$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
fit <- train(y~., data = vowel.train, method = "rf")
getTree(fit)
getTree(fit,k=2)
getTree(fit$finalModel)
?varimp
library(caret)
?varimp
?varImp
varImp(fit)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
data1 <- segmentationOriginal[segmentationOriginal$Case=="",]
data1
segmentationOriginal$Case
Train <- segmentationOriginal$Case=="Test"
data1 <- segmentationOriginal[Train,]
data1Tet <- segmentationOriginal[-Train,]
dim(data1)
dim(data1Test)
dim(data1Tet)
Train
dim(segmentationOriginal)
Train <- segmentationOriginal[segmentationOriginal$Case=="Train",]
Test <- segmentationOriginal[segmentationOriginal$Case=="Test",]
dim(Test)
dim(Train)
set.seed(125)
fit <- train(Class ~ ., data = Train, method = "rpart")
fit$finalModel
plot(fit$finalModel)
plot(fit$finalModel, uniform = TRUE, main = "classification")
text(fit$finalModel)
text(fit$finalModel, use.n =TRUE)
text(fit$finalModel, use.n =TRUE, all=TRUE)
text(fit$finalModel, use.n =TRUE, all=TRUE, cex - 0.8)
text(fit$finalModel, use.n =TRUE, all=TRUE, cex = 0.8)
plot(fit$finalModel, uniform = TRUE, main = "classification")
text(fit$finalModel, use.n =TRUE, all=TRUE, cex = 0.8)
fancyRpartPlotfit$finalModel)
?fancyRpartPlot
install.packages(rattle)
install.packages("rattle")
library("rattle")
?fancyRpartPlot
fancyRpartPlot(fit$finalModel)
install.packages("rpart.plot")
fancyRpartPlot(fit$finalModel)
train <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv")
test <- read.csv("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv")
summary(train)
names(train)
dim(train)
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-training.csv", method = "curl")
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-training.csv", method = curl)
download.file(url = "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", destfile = "pml-training.csv")
is.na(train)
temp <- sapply(X = train, function(x){sum(is.na(x))})
temp
sum(is.na(train[,18]))
(is.na(train[,18]))
dim(train)
dim(temo)
dim(temp)
length(temp)
misssingCount <- sapply(X = train, function(x){sum(is.na(x))})
summary(misssingcount)
summary(misssingCount)
missingCount <- sapply(X = train, function(x){sum(is.na(x))})
summary(missingCount)
dim(missingCount)
length(missingCount)
missingCount[18]
missingCount[17]
missingcount[18] > 0
missingCount[18] > 0
missingCount[17] > 0
missingCount <- sapply(missingCount, function(x) {if (x>0) then 1 else 0})
missingCount <- sapply(missingCount, x>0)
missingCount <- sapply(X = train, function(x){sum(is.na(x)) > 0})
missingCount
missingCount$stddev_pitch_forearm
missingCount$accel_forearm_x
missingCount
missingCount[18]
missingCount[17]
missingCountI <- missingCount==TRUE
missingCountI
missingCountI <- missingCount== "TRUE"
missingCountI
missingCountI <- sapply(missingCount, function(x) {if(x == "TRUE") return x})
missingCountI <- sapply(missingCount, function(x) {if(x == "TRUE"): return x})
missingCountI <- sapply(missingCount, function(x) {if(x == "TRUE"): {return x}})
missingCountI <- sapply(missingCount, function(x) { if(x == "TRUE") {return x}})
missingCount <- sapply(X = train, function(x){sum(is.na(x))})
missingCountI <- which(missingCount>10000)
missingCountI
trainN <- train[,-missingCountI]
dim(trainN)
testN <- test[,-missingCountI]
dim(trainN)
names(trainN)
fit1 <- train(classe ~ . , data = trainN, method = "rfcv")
install.packages("randomForest")
library("randomForest")
inTrainN <- createDataPartition(y = trainN$classe , p=0.75, list = FALSE)
dim(inTrain)
dim(inTrainN)
trainN1 <- trainN[inTrainN,]
trainN2 <- trainN[-inTrainN,]
fit1 <- train(classe ~ . , data = trainN1, method = "rf")
delete(temp)
remove(temp)
install.packages("doParallel")
library(doParallel)
registerDoParallel(cores=4)
fit1 <- train(classe ~ . , data = trainN1, method = "rf", preProcess = "pca")
registerDoParallel(cores=4)
registerDoParallel(cores=2)
remove(fit1)
fit1 <- train(classe ~ . , data = trainN1, method = "rf", preProcess = "pca")
require(doParallel)
require(caret)
registerDoParallel(cores=2)
fit1 <- train(classe ~ . , data = trainN1, method = "rpart", preProcess = "pca")
?dbscan
require(fpc)
?dbscan
library(devtools)
install.packages(slidify)
install.packages("slidify")
install_github("slidify","ramnathv")
?install_github
install_github(username = "slidify",auth_token = "ramnathv")
install_github(username =  "slidify", repo = "ramnathv")
install_github(username =  "slidify/ramnathv", repo = "ramnathv")
install_github(username =  "slidify", ref = "ramnathv")
install_github(repo =  "slidify", username =  = "ramnathv")
install_github(repo =  "slidify", username = "ramnathv")
install_github(repo =  "slidifyLibraries", username = "ramnathv")
library(slidify)
library("slidify")
install.packages("stringr")
library("slidify")
update.packages("stringr")
library("slidify")
library("slidify")
library("slidify")
library("slidify")
remove.packages("stringr")
install.packages("stringr")
install.packages("stringr")
library("slidify")
update.packages("stringr")
library("slidify")
install_version("stringr", version="0.6.2")
install_version("stringr", version="0.6.2", type = "source")
install_github("ramnathv/slidify", "ramnathv")
install_github("raamnathv/slidifyLibraries")
install_github("raamnathv/slidifyLibraries", "ramnathv")
install_github("slidifyLibraries", "ramnathv")
library("slidify")
remove.packages("stringr")
library("slidify")
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
publish(title = 'statNewCos', 'statNewCo.html', host = 'rpubs')
library(rpubs)
library(slidify)
library(rpubs)
publish(title = 'statNewCos', 'statNewCo.html', host = 'rpubs')
publish(title = 'statNewCos', 'statNewCo-rpubs', host = 'rpubs')
publish(title = 'statNewCos', 'statNewCo-rpubs.html', host = 'rpubs')
publish(title = 'statNewCos', '/statNewCo-rpubs.html', host = 'rpubs')
setwd("C:/Users/udevani/Desktop/Rpro/StatNewCos")
publish(title = 'statNewCos', '/statNewCo-rpubs.html', host = 'rpubs')
publish(title = 'statNewCos', 'statNewCo-rpubs.html', host = 'rpubs')
publish(title = 'statNewCos', 'statNewCo.html', host = 'rpubs')
library(knitR)
library("knitR")
library("KnitR")
library("knitr")
publish(title = 'statNewCos', 'statNewCo.html', host = 'rpubs')
publish(title = 'statNewCos', 'statNewCo.html', host = 'rpubs')
publish(title = 'statNewCos', 'statNewCo.html', host = 'rpubs')
